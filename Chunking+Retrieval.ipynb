{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4569777e-db7c-4858-864f-6ab0dadfda89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilin/RAG/RAG-Challenge/rag-challenge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"Deepseek-r1.pdf\")\n",
    "pages = loader.load()\n",
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdedc8ee-0b0b-4029-a91e-f7d0f56936c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace(\"\\xa0\", \" \")  \n",
    "    text = re.sub(r\"\\s+\\n\", \"\\n\", text)  \n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)  \n",
    "    text = re.sub(r\"-\\n\", \"\", text)  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510904f9-1e7d-4a2a-9adb-15801d863ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pages:\n",
    "    p.page_content = clean_text(p.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9f52b-4217-4750-ab70-2ba37b369491",
   "metadata": {},
   "source": [
    "# Chunking\n",
    "## Fixed-size chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dbdfaaf-4603-4a90-94ff-9001027f8cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "fixed_chunks = splitter.split_documents(pages)\n",
    "len(fixed_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfe9b3b-fb68-4921-a347-4cf6014f5876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 92 chunks ‚Üí chunks_fixed.json\n"
     ]
    }
   ],
   "source": [
    "# Convert to JSON serializable format\n",
    "chunks_json = [\n",
    "    {\"id\": i, \"text\": chunk.page_content}\n",
    "    for i, chunk in enumerate(fixed_chunks)\n",
    "]\n",
    "\n",
    "# Save\n",
    "with open(\"chunks_fixed.json\", \"w\") as f:\n",
    "    json.dump(chunks_json, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(chunks_json)} chunks ‚Üí chunks_fixed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eddca6a-302b-416e-b9ba-75becac8c99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fixed Chunk #0 =====\n",
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\n",
      "reasoning behavio\n",
      "\n",
      "\n",
      "===== Fixed Chunk #1 =====\n",
      "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
      "DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\n",
      "research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\n",
      "(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "GPQA Diamond\n",
      "(Pass@1\n",
      "\n",
      "\n",
      "===== Fixed Chunk #2 =====\n",
      "79.8\n",
      "96.3\n",
      "71.5\n",
      "97.3\n",
      "90.8\n",
      "49.2\n",
      "79.2\n",
      "96.6\n",
      "75.7\n",
      "96.4\n",
      "91.8\n",
      "48.9\n",
      "72.6\n",
      "90.6\n",
      "62.1\n",
      "94.3\n",
      "87.4\n",
      "36.8\n",
      "63.6\n",
      "93.4\n",
      "60.0\n",
      "90.0\n",
      "85.2\n",
      "41.6\n",
      "39.2\n",
      "58.7 59.1\n",
      "90.2\n",
      "88.5\n",
      "42.0\n",
      "DeepSeek-R1 OpenAI-o1-1217 DeepSeek-R1-32B OpenAI-o1-mini DeepSeek-V3\n",
      "Figure 1 |Benchmark performance of DeepSeek-R1.\n",
      "arXiv:2501.12948v1  [cs.CL]  22 Jan 2025\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(fixed_chunks[:3]):\n",
    "    print(f\"===== Fixed Chunk #{i} =====\")\n",
    "    print(c.page_content[:500]) \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bd397-50cd-4cde-babd-ccace7d5c8da",
   "metadata": {},
   "source": [
    "## Content chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1416b85-4ec1-4589-a29b-7811b5c87b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "import re\n",
    "\n",
    "def split_by_headings(text):\n",
    "    # ÂåπÈÖç ‚Äú1 Introduction‚Äù / ‚Äú2.3 DeepSeek-R1-Zero‚Äù Á≠âÊ†ºÂºè\n",
    "    pattern = r\"\\n(?=\\d[\\d\\.]*\\s[A-Z])\"\n",
    "    parts = re.split(pattern, text)\n",
    "    \n",
    "    docs = []\n",
    "    for part in parts:\n",
    "        clean_part = part.strip()\n",
    "        if clean_part:\n",
    "            docs.append(Document(page_content=clean_part))\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c0b19d-014f-41e6-ac90-63675ff51a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = \"\\n\".join([p.page_content for p in pages])\n",
    "heading_chunks = split_by_headings(full_text)\n",
    "len(heading_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4a06e-93af-4354-b6c5-9fa508653e0a",
   "metadata": {},
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,\n",
    "    chunk_overlap=150\n",
    ")\n",
    "\n",
    "final_chunks = []\n",
    "\n",
    "for doc in heading_chunks:\n",
    "    small_chunks = splitter.split_text(doc.page_content)\n",
    "    for chunk in small_chunks:\n",
    "        final_chunks.append(Document(page_content=chunk))\n",
    "        \n",
    "len(final_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "396818fe-1852-4c7e-ada5-f4f0e566c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Heading Chunk #0 =====\n",
      "2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\n",
      "Reinforcement learning has demonstrated significant effectiveness in reasoning tasks, as evidenced by our previous works (Shao et al., 2024; Wang et al., 2023). However, these works\n",
      "heavily depended on supervised data, which are time-intensive to gather. In this section, we\n",
      "explore the potential of LLMs to develop reasoning capabilities without any supervised data,\n",
      "focusing on their self-evolution through a pure reinforcement learni\n",
      "\n",
      "\n",
      "===== Heading Chunk #1 =====\n",
      "2.2.1. Reinforcement Learning Algorithm\n",
      "Group Relative Policy OptimizationIn order to save the training costs of RL, we adopt Group\n",
      "Relative Policy Optimization (GRPO) (Shao et al., 2024), which foregoes the critic model that is\n",
      "typically the same size as the policy model, and estimates the baseline from group scores instead.\n",
      "Specifically, for each question ùëû, GRPO samples a group of outputs {ùëú1, ùëú2, ¬∑¬∑¬∑ , ùëúùê∫}from the old\n",
      "policy ùúãùúÉùëúùëôùëë and then optimizes the policy model ùúãùúÉ by maximizing the foll\n",
      "\n",
      "\n",
      "===== Heading Chunk #2 =====\n",
      "5\n",
      "A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\n",
      "The assistant first thinks about the reasoning process in the mind and then provides the user\n",
      "with the answer. The reasoning process and answer are enclosed within <think> </think> and\n",
      "<answer> </answer> tags, respectively, i.e., <think> reasoning process here </think>\n",
      "<answer> answer here </answer>. User: prompt. Assistant:\n",
      "Table 1 |Template for DeepSeek-R1-Zero. prompt will be replaced with the \n",
      "\n",
      "\n",
      "===== Heading Chunk #3 =====\n",
      "2.2.2. Reward Modeling\n",
      "The reward is the source of the training signal, which decides the optimization direction of RL.\n",
      "To train DeepSeek-R1-Zero, we adopt a rule-based reward system that mainly consists of two\n",
      "types of rewards:\n",
      "‚Ä¢ Accuracy rewards: The accuracy reward model evaluates whether the response is correct.\n",
      "For example, in the case of math problems with deterministic results, the model is required\n",
      "to provide the final answer in a specified format (e.g., within a box), enabling reliable\n",
      "\n",
      "\n",
      "\n",
      "===== Heading Chunk #4 =====\n",
      "2.2.3. Training Template\n",
      "To train DeepSeek-R1-Zero, we begin by designing a straightforward template that guides\n",
      "the base model to adhere to our specified instructions. As depicted in Table 1, this template\n",
      "requires DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer.\n",
      "We intentionally limit our constraints to this structural format, avoiding any content-specific\n",
      "biases‚Äîsuch as mandating reflective reasoning or promoting particular problem-solving strategies‚Äîto ens\n",
      "\n",
      "\n",
      "===== Heading Chunk #5 =====\n",
      "2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero\n",
      "Performance of DeepSeek-R1-Zero Figure 2 depicts the performance trajectory of DeepSeekR1-Zero on the AIME 2024 benchmark throughout the RL training process. As illustrated,\n",
      "DeepSeek-R1-Zero demonstrates a steady and consistent enhancement in performance as the\n",
      "RL training advances. Notably, the average pass@1 score on AIME 2024 shows a significant\n",
      "increase, jumping from an initial 15.6% to an impressive 71.0%, reachin\n",
      "\n",
      "\n",
      "===== Heading Chunk #6 =====\n",
      "6\n",
      "Model AIME 2024 MATH-500 GPQA LiveCode CodeForcesDiamond Bench\n",
      "pass@1 cons@64 pass@1 pass@1 pass@1 rating\n",
      "OpenAI-o1-mini 63.6 80.0 90.0 60.0 53.8 1820\n",
      "OpenAI-o1-0912 74.4 83.3 94.8 77.3 63.4 1843\n",
      "DeepSeek-R1-Zero 71.0 86.7 95.9 73.3 50.0 1444\n",
      "Table 2 |Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related\n",
      "benchmarks.\n",
      "Figure 2 |AIME accuracy of DeepSeek-R1-Zero during training. For each question, we sample\n",
      "16 responses and calculate the overall average accuracy to ensure a sta\n",
      "\n",
      "\n",
      "===== Heading Chunk #7 =====\n",
      "8\n",
      "Question: If ùëé >1, then the sum of the real solutions of\n",
      "‚àöÔ∏Å\n",
      "ùëé‚àí‚àö\n",
      "ùëé+ùë• = ùë• is equal to\n",
      "Response: <think>\n",
      "To solve the equation\n",
      "‚àöÔ∏Å\n",
      "ùëé‚àí‚àö\n",
      "ùëé+ùë• = ùë•, let‚Äôs start by squaring both ¬∑¬∑¬∑\u0010‚àöÔ∏Å\n",
      "ùëé‚àí‚àö\n",
      "ùëé+ùë•\n",
      "\u00112\n",
      "= ùë•2 =‚áí ùëé‚àí‚àö\n",
      "ùëé+ùë• = ùë•2.\n",
      "Rearrange to isolate the inner square root term:\n",
      "(ùëé‚àíùë•2)2 = ùëé+ùë• =‚áí ùëé2 ‚àí2ùëéùë•2 +(ùë•2)2 = ùëé+ùë• =‚áí ùë•4 ‚àí2ùëéùë•2 ‚àíùë•+(ùëé2 ‚àíùëé)= 0\n",
      ". . .\n",
      "Wait, wait. Wait. That‚Äôs an aha moment I can flag here.\n",
      "Let‚Äôs reevaluate this step-by-step to identify if the correct sum can be ¬∑¬∑¬∑\n",
      "We started with the equation:‚àöÔ∏Å\n",
      "ùëé‚àí‚àö\n",
      "\n",
      "\n",
      "\n",
      "===== Heading Chunk #8 =====\n",
      "2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\n",
      "Inspired by the promising results of DeepSeek-R1-Zero, two natural questions arise: 1) Can\n",
      "reasoning performance be further improved or convergence accelerated by incorporating a small\n",
      "amount of high-quality data as a cold start? 2) How can we train a user-friendly model that\n",
      "not only produces clear and coherent Chains of Thought (CoT) but also demonstrates strong\n",
      "general capabilities? To address these questions, we design a pipeline to tr\n",
      "\n",
      "\n",
      "===== Heading Chunk #9 =====\n",
      "2.3.1. Cold Start\n",
      "Unlike DeepSeek-R1-Zero, to prevent the early unstable cold start phase of RL training from\n",
      "the base model, for DeepSeek-R1 we construct and collect a small amount of long CoT data\n",
      "to fine-tune the model as the initial RL actor. To collect such data, we have explored several\n",
      "approaches: using few-shot prompting with a long CoT as an example, directly prompting\n",
      "models to generate detailed answers with reflection and verification, gathering DeepSeek-R1Zero outputs in a readable f\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, c in enumerate(heading_chunks[30:40]):\n",
    "    print(f\"===== Heading Chunk #{i} =====\")\n",
    "    print(c.page_content[:500])  # Âè™ÊâìÂç∞ÂâçÈù¢‰∏ÄÈÉ®ÂàÜ\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bca23b-b4aa-411e-8085-3e630b507f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\n",
      "reasoning behaviors. However, it encounters challenges such as poor readability, and language\n",
      "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
      "DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeekR1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\n",
      "research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\n",
      "(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
      "AIME 2024\n",
      "(Pass@1)\n",
      "Codeforces\n",
      "(Percentile)\n",
      "GPQA Diamond\n",
      "(Pass@1)\n",
      "MATH-500\n",
      "(Pass@1)\n",
      "MMLU\n",
      "(Pass@1)\n",
      "SWE-bench Verified\n",
      "(Resolved)\n",
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100Accuracy / Percentile (%)\n",
      "79.8\n",
      "96.3\n",
      "71.5\n",
      "97.3\n",
      "90.8\n",
      "49.2\n",
      "79.2\n",
      "96.6\n",
      "75.7\n",
      "96.4\n",
      "91.8\n",
      "48.9\n",
      "72.6\n",
      "90.6\n",
      "62.1\n",
      "94.3\n",
      "87.4\n",
      "36.8\n",
      "63.6\n",
      "93.4\n",
      "60.0\n",
      "90.0\n",
      "85.2\n",
      "41.6\n",
      "39.2\n",
      "58.7 59.1\n",
      "90.2\n",
      "88.5\n"
     ]
    }
   ],
   "source": [
    "print(heading_chunks[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d56539c-dc96-4492-b1da-c9c29c8f423a",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "## Dense Search (Semantice embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ce2bc4-c27f-47e7-87b8-91fc52eb9fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from fastembed import TextEmbedding, SparseTextEmbedding\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5b21642-480a-4bdf-9574-ea79864b0381",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(path=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b98b495-cb9e-44fe-b652-49e4838f70f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-base-en',\n",
       "  'sources': {'hf': 'Qdrant/fast-bge-base-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.42,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-base-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-base-en-v1.5-onnx-q',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-base-en-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.21,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-large-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-large-en-v1.5-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-zh-v1.5',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-zh-v1.5',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "  'sources': {'hf': 'mixedbread-ai/mxbai-embed-large-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m',\n",
       "  'sources': {'hf': 'Snowflake/snowflake-arctic-embed-m',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.43,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-m-long',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.54,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-l',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-l',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.02,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-clip-v1',\n",
       "  'sources': {'hf': 'jinaai/jina-clip-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/text_model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.55,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'Qdrant/clip-ViT-B-32-text',\n",
       "  'sources': {'hf': 'Qdrant/clip-ViT-B-32-text',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.25,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-base-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-small-en',\n",
       "  'sources': {'hf': 'xenova/jina-embeddings-v2-small-en',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.12,\n",
       "  'additional_files': [],\n",
       "  'dim': 512,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-de',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-de',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_fp16.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.32,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-code',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-code',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-zh',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v2-base-es',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v2-base-es',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.64,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-base',\n",
       "  'sources': {'hf': 'thenlper/gte-base',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.44,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'thenlper/gte-large',\n",
       "  'sources': {'hf': 'qdrant/gte-large-onnx',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 1.2,\n",
       "  'additional_files': [],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1.5-Q',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1.5',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model_quantized.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'nomic-ai/nomic-embed-text-v1',\n",
       "  'sources': {'hf': 'nomic-ai/nomic-embed-text-v1',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.52,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.22,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
       "  'sources': {'hf': 'xenova/paraphrase-multilingual-mpnet-base-v2',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 1.0,\n",
       "  'additional_files': [],\n",
       "  'dim': 768,\n",
       "  'tasks': {}},\n",
       " {'model': 'intfloat/multilingual-e5-large',\n",
       "  'sources': {'hf': 'qdrant/multilingual-e5-large-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/fast-multilingual-e5-large.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 2.24,\n",
       "  'additional_files': ['model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {}},\n",
       " {'model': 'jinaai/jina-embeddings-v3',\n",
       "  'sources': {'hf': 'jinaai/jina-embeddings-v3',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.',\n",
       "  'license': 'cc-by-nc-4.0',\n",
       "  'size_in_GB': 2.29,\n",
       "  'additional_files': ['onnx/model.onnx_data'],\n",
       "  'dim': 1024,\n",
       "  'tasks': {'retrieval.query': 0,\n",
       "   'retrieval.passage': 1,\n",
       "   'separation': 2,\n",
       "   'classification': 3,\n",
       "   'text-matching': 4}}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "346358bb-54f0-40e4-8aa2-a40c5f9d5899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model\": \"BAAI/bge-small-zh-v1.5\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/bge-small-zh-v1.5\",\n",
      "    \"url\": \"https://storage.googleapis.com/qdrant-fastembed/fast-bge-small-zh-v1.5.tar.gz\",\n",
      "    \"_deprecated_tar_struct\": true\n",
      "  },\n",
      "  \"model_file\": \"model_optimized.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.09,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"Qdrant/clip-ViT-B-32-text\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"model.onnx\",\n",
      "  \"description\": \"Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year\",\n",
      "  \"license\": \"mit\",\n",
      "  \"size_in_GB\": 0.25,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n",
      "{\n",
      "  \"model\": \"jinaai/jina-embeddings-v2-small-en\",\n",
      "  \"sources\": {\n",
      "    \"hf\": \"xenova/jina-embeddings-v2-small-en\",\n",
      "    \"url\": null,\n",
      "    \"_deprecated_tar_struct\": false\n",
      "  },\n",
      "  \"model_file\": \"onnx/model.onnx\",\n",
      "  \"description\": \"Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.\",\n",
      "  \"license\": \"apache-2.0\",\n",
      "  \"size_in_GB\": 0.12,\n",
      "  \"additional_files\": [],\n",
      "  \"dim\": 512,\n",
      "  \"tasks\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "for model in TextEmbedding.list_supported_models():\n",
    "    if model[\"dim\"] == EMBEDDING_DIMENSIONALITY:\n",
    "        print(json.dumps(model, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c53b8c-0bfc-4ba9-b59e-f2d8a2c467ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embedder = TextEmbedding(model_name=\"BAAI/bge-large-en-v1.5\")\n",
    "sparse_embedder = SparseTextEmbedding(model_name=\"qdrant/bm25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aba2dcfc-1bd7-4431-94db-fec8da3292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = heading_chunks \n",
    "# chunks = fixed_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30dd4a49-c3c5-4bd5-8102-9d0b59e8f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [c.page_content for c in chunks]\n",
    "ids = list(range(len(texts)))\n",
    "payloads = [{\"chunk_id\": i, \"text\": texts[i]} for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df81db06-6bda-4767-a758-96ad11410f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/27235495.py:4: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense Embedding\n",
    "dense_vectors = list(dense_embedder.embed(texts))\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"deepseek_dense\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,              \n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2cc5b-03c9-4e34-b644-83910edb5ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=\"deepseek_dense\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=ids[i],\n",
    "            vector=dense_vectors[i],\n",
    "            payload=payloads[i]\n",
    "        )\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61b02c-5822-4098-ac5b-ec242ee20dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which reinforcement learning algorithm does DeepSeek-R1 use?\"\n",
    "\n",
    "query_vector = next(dense_embedder.embed([query]))\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=\"deepseek_dense\",\n",
    "    query=query_vector,\n",
    "    limit=5\n",
    ").points\n",
    "\n",
    "for hit in results:\n",
    "    print(\"\\nChunk ID:\", hit.payload[\"chunk_id\"], \"Score:\", hit.score)\n",
    "    print(hit.payload[\"text\"][:400], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3d9d9-4b68-474c-908e-a529ca57d9d1",
   "metadata": {},
   "source": [
    "## Sparse Search (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3470f3eb-2981-4b92-886a-825ed8f485f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_vectors = list(sparse_embedder.embed(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc708185-762d-4a1a-9e0f-54cf94ca8a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseEmbedding(values=array([2.0149613 , 1.9779911 , 1.09444229, 1.88298228, 1.46171814,\n",
       "       1.09444229, 1.46171814, 1.46171814, 1.46171814, 1.09444229,\n",
       "       1.46171814, 1.09444229, 1.09444229, 1.46171814, 1.09444229,\n",
       "       1.09444229, 1.64582116, 1.75643225, 1.46171814, 1.09444229,\n",
       "       1.09444229, 1.64582116, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.46171814, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.92255925, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.75643225, 1.09444229, 1.46171814, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.64582116, 1.09444229, 1.09444229,\n",
       "       1.46171814, 1.09444229, 1.09444229, 1.46171814, 1.75643225,\n",
       "       1.64582116, 1.64582116, 1.09444229, 1.46171814, 1.09444229,\n",
       "       1.75643225, 1.09444229, 1.83023528, 1.83023528, 1.09444229,\n",
       "       1.46171814, 1.64582116, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229, 1.09444229, 1.09444229,\n",
       "       1.09444229, 1.09444229, 1.09444229]), indices=array([ 626054326, 1322494343,   92037970, 1704236722, 1607792561,\n",
       "        586932639, 2065015680, 1564762454, 1644170059, 1653355191,\n",
       "        769443847, 1746685302,   15051562, 1376864891, 1443829736,\n",
       "        243731433, 1172383616, 2006536704, 1190790875, 2117458213,\n",
       "       1005783980, 1590008068, 1477105254,  684999793, 1096710751,\n",
       "        566055922,  999098644, 1549042339, 1908700427, 2063746700,\n",
       "       1821653700,  916214203, 2073907658,  727594685, 2061075054,\n",
       "        527400520,  252385603,  379738165, 1050123329,  141936911,\n",
       "        503090393,  345639140,  842430915, 1977712632, 2132027491,\n",
       "       1728527060,  403938802,  150695120, 2135526316,  780280564,\n",
       "       1105706408, 1553669594, 1561499504,  989116115, 1323278866,\n",
       "        236277287, 1661675969, 1721384439,  713705115, 1808847888,\n",
       "       1763574823, 1100855371,  937927958, 2091876921,  286434387,\n",
       "       1765639896,  176373589, 1810453357, 1010302424,  150599154,\n",
       "        949829753, 1409321042,  473537453, 1157691434, 1296698535,\n",
       "       1010104944, 1599113826,  548814886, 1684747337, 1555540962,\n",
       "        390204765,  891071748,  114618403, 1934479942,  924587953,\n",
       "        449651267,  102022374,  999280890, 1832248279, 1267155205,\n",
       "       1031872395, 1363632613,  764297089,  163077544, 1784631546,\n",
       "        388471277, 1127017311, 1146879040,  790307948, 1114505193,\n",
       "        420074073,  264741300,  109999459, 1394226660,  496426677,\n",
       "       1305218356,   43552621,   19522071,  670727360, 2058237543,\n",
       "        602572328,  516830072,  610518005, 1536080379,  613148321,\n",
       "       1649421877,  427706599, 1144321365, 1611841122,  877198705,\n",
       "        623624099, 1372587672,  192365738,  697211857,  834769235,\n",
       "       1237113930, 1280193368, 2046836901]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0e6b0a-58ff-4148-9dd4-bba547ee0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.collection_exists(\"deepseek_sparse\"):\n",
    "    client.delete_collection(\"deepseek_sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe3ac6cd-bc53-46c9-826b-c54018355c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/2646633453.py:1: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"deepseek_sparse\",\n",
    "    vectors_config={},\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f6974fe-0863-47d3-a11e-020973cceb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_vectors = list(sparse_embedder.embed(texts))\n",
    "\n",
    "client.upload_points(\n",
    "    collection_name=\"deepseek_sparse\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=i,\n",
    "            vector={\"bm25\": bm25_vectors[i].as_object()},\n",
    "            payload={\"chunk_id\": i, \"text\": texts[i]}\n",
    "        )\n",
    "        for i in range(len(texts))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ddde7e0-df01-4bd3-bc38-fdbe5b36d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk ID: 30 Score: 8.353005409240723\n",
      "2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\n",
      "Reinforcement learning has demonstrated significant effectiveness in reasoning tasks, as evidenced by our previous works (Shao et al., 2024; Wang et al., 2023). However, these works\n",
      "heavily depended on supervised data, which are time-intensive to gather. In this section, we\n",
      "explore the potential of LLMs to develop reasoning capabiliti ...\n",
      "\n",
      "Chunk ID: 25 Score: 8.22844409942627\n",
      "1. Introduction\n",
      "In recent years, Large Language Models (LLMs) have been undergoing rapid iteration and\n",
      "evolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap\n",
      "towards Artificial General Intelligence (AGI).\n",
      "Recently, post-training has emerged as an important component of the full training pipeline.\n",
      "It has been shown to enhance accuracy on reasoning tasks, align w ...\n",
      "\n",
      "Chunk ID: 29 Score: 6.960752487182617\n",
      "2.1. Overview\n",
      "Previous work has heavily relied on large amounts of supervised data to enhance model\n",
      "performance. In this study, we demonstrate that reasoning capabilities can be significantly\n",
      "improved through large-scale reinforcement learning (RL), even without using supervised\n",
      "fine-tuning (SFT) as a cold start. Furthermore, performance can be further enhanced with\n",
      "the inclusion of a small amount ...\n",
      "\n",
      "Chunk ID: 50 Score: 6.9266228675842285\n",
      "4.1. Distillation v.s. Reinforcement Learning\n",
      "In Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive\n",
      "results. However, there is still one question left: can the model achieve comparable performance\n",
      "through the large-scale RL training discussed in the paper without distillation?\n",
      "To answer this question, we conduct large-scale RL training on Qwen-32B-Base u ...\n",
      "\n",
      "Chunk ID: 53 Score: 6.744166374206543\n",
      "5. Conclusion, Limitations, and Future Work\n",
      "In this work, we share our journey in enhancing model reasoning abilities through reinforcement\n",
      "learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\n",
      "data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\n",
      "leveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 ...\n"
     ]
    }
   ],
   "source": [
    "query = \"Which reinforcement learning algorithm does DeepSeek-R1 use?\"\n",
    "\n",
    "query_sparse = next(sparse_embedder.query_embed(query))\n",
    "\n",
    "results = client.query_points(\n",
    "    collection_name=\"deepseek_sparse\",\n",
    "    query=models.SparseVector(**query_sparse.as_object()),\n",
    "    using=\"bm25\",\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ").points\n",
    "\n",
    "for hit in results:\n",
    "    print(\"\\nChunk ID:\", hit.payload[\"chunk_id\"], \"Score:\", hit.score)\n",
    "    print(hit.payload[\"text\"][:400], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05418a7-4b0c-4b80-9c9d-a7af1ba452d8",
   "metadata": {},
   "source": [
    "## Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "575f543c-80c7-4228-8302-349056c51873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastembed import TextEmbedding, SparseTextEmbedding, LateInteractionTextEmbedding\n",
    "from qdrant_client import QdrantClient, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c612655-74d4-4029-a199-3123ce0bf3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = TextEmbedding(\"BAAI/bge-large-en-v1.5\")\n",
    "sparse_model = SparseTextEmbedding(\"Qdrant/bm25\")\n",
    "late_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8ee8865-8eba-465c-9b73-b1d16b9b3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [c.page_content for c in heading_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee4c6b55-f9ce-4aca-98b8-d3e12e06ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_embeddings = list(dense_model.embed(documents))\n",
    "bm25_embeddings = list(sparse_model.embed(documents))\n",
    "late_embeddings = list(late_model.embed(documents))   # Ê≥®ÊÑèÔºöËøôÊòØ list of list of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "810457ce-1099-4c8b-8397-288d7d205f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/322785062.py:3: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import Distance, VectorParams, models\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"deepseek_hybrid\",\n",
    "    vectors_config={\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=len(dense_embeddings[0]),\n",
    "            distance=models.Distance.COSINE\n",
    "        ),\n",
    "        \"colbert\": models.VectorParams(\n",
    "            size=len(late_embeddings[0][0]),\n",
    "            distance=models.Distance.COSINE,\n",
    "            multivector_config=models.MultiVectorConfig(\n",
    "                comparator=models.MultiVectorComparator.MAX_SIM,\n",
    "            ),\n",
    "            hnsw_config=models.HnswConfigDiff(m=0)  # Á¶ÅÁî® HNSWÔºàColBERT rerank ÂøÖÈ°ªÁ¶ÅÁî®Ôºâ\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF\n",
    "        )\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dde37a1-697d-4a07-a3be-743b7178b181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "points = []\n",
    "for idx, (dense, bm25, late, doc) in enumerate(\n",
    "    zip(dense_embeddings, bm25_embeddings, late_embeddings, documents)\n",
    "):\n",
    "    point = PointStruct(\n",
    "        id=idx,\n",
    "        vector={\n",
    "            \"jina-small\": dense,\n",
    "            \"bm25\": bm25.as_object(),\n",
    "            \"colbert\": late\n",
    "        },\n",
    "        payload={\"chunk_id\": idx, \"text\": doc}\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "client.upsert(collection_name=\"deepseek_hybrid\", points=points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "421f70f3-7324-4b41-ae40-2b8009f48582",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Which reinforcement learning algorithm does DeepSeek-R1 use?\"\n",
    "\n",
    "query_dense = next(dense_model.query_embed(query))\n",
    "query_sparse = next(sparse_model.query_embed(query))\n",
    "query_late = next(late_model.query_embed(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "067e70ac-f07e-4240-8b1d-5b24963cdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrefetchÔºàDense + SparseÔºâHybrid Retrieval\n",
    "prefetch = [\n",
    "    models.Prefetch(\n",
    "        query=query_dense,\n",
    "        using=\"jina-small\",\n",
    "        limit=20\n",
    "    ),\n",
    "    models.Prefetch(\n",
    "        query=models.SparseVector(**query_sparse.as_object()),\n",
    "        using=\"bm25\",\n",
    "        limit=20\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ad4a4b2-fb27-4623-996e-52c7892db193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHUNK: 30 SCORE: 25.6588256074936\n",
      "2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model\n",
      "Reinforcement learning has demonstrated significant effectiveness in reasoning tasks, as evidenced by our previous works (Shao et al., 2024; Wang et al., 2023). However, these works\n",
      "heavily depended on supervised data, which are time-intensive to gather. In this section, we\n",
      "explore the potential of LLMs to develop reasoning capabiliti ...\n",
      "\n",
      "CHUNK: 7 SCORE: 24.348006591472615\n",
      "2.2 DeepSeek-R1-Zero: Reinforcement Learning on the Base Model . . . . . . . . . . 5 ...\n",
      "\n",
      "CHUNK: 12 SCORE: 23.841955517857894\n",
      "2.3 DeepSeek-R1: Reinforcement Learning with Cold Start . . . . . . . . . . . . . . . 9 ...\n",
      "\n",
      "CHUNK: 38 SCORE: 23.553651692000606\n",
      "2.3. DeepSeek-R1: Reinforcement Learning with Cold Start\n",
      "Inspired by the promising results of DeepSeek-R1-Zero, two natural questions arise: 1) Can\n",
      "reasoning performance be further improved or convergence accelerated by incorporating a small\n",
      "amount of high-quality data as a cold start? 2) How can we train a user-friendly model that\n",
      "not only produces clear and coherent Chains of Thought (CoT) but a ...\n",
      "\n",
      "CHUNK: 0 SCORE: 23.294040863407773\n",
      "DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
      "Reinforcement Learning\n",
      "DeepSeek-AI\n",
      "research@deepseek.com\n",
      "Abstract\n",
      "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
      "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
      "Th ...\n",
      "\n",
      "CHUNK: 25 SCORE: 23.242542640717325\n",
      "1. Introduction\n",
      "In recent years, Large Language Models (LLMs) have been undergoing rapid iteration and\n",
      "evolution (Anthropic, 2024; Google, 2024; OpenAI, 2024a), progressively diminishing the gap\n",
      "towards Artificial General Intelligence (AGI).\n",
      "Recently, post-training has emerged as an important component of the full training pipeline.\n",
      "It has been shown to enhance accuracy on reasoning tasks, align w ...\n",
      "\n",
      "CHUNK: 50 SCORE: 22.96138576148924\n",
      "4.1. Distillation v.s. Reinforcement Learning\n",
      "In Section 3.2, we can see that by distilling DeepSeek-R1, the small model can achieve impressive\n",
      "results. However, there is still one question left: can the model achieve comparable performance\n",
      "through the large-scale RL training discussed in the paper without distillation?\n",
      "To answer this question, we conduct large-scale RL training on Qwen-32B-Base u ...\n",
      "\n",
      "CHUNK: 40 SCORE: 22.815249151620975\n",
      "2.3.2. Reasoning-oriented Reinforcement Learning\n",
      "After fine-tuning DeepSeek-V3-Base on the cold start data, we apply the same large-scale\n",
      "reinforcement learning training process as employed in DeepSeek-R1-Zero. This phase focuses\n",
      "on enhancing the model‚Äôs reasoning capabilities, particularly in reasoning-intensive tasks such\n",
      "as coding, mathematics, science, and logic reasoning, which involve well-d ...\n",
      "\n",
      "CHUNK: 53 SCORE: 22.522339226497465\n",
      "5. Conclusion, Limitations, and Future Work\n",
      "In this work, we share our journey in enhancing model reasoning abilities through reinforcement\n",
      "learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\n",
      "data, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\n",
      "leveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 ...\n",
      "\n",
      "CHUNK: 29 SCORE: 22.422038848411944\n",
      "2.1. Overview\n",
      "Previous work has heavily relied on large amounts of supervised data to enhance model\n",
      "performance. In this study, we demonstrate that reasoning capabilities can be significantly\n",
      "improved through large-scale reinforcement learning (RL), even without using supervised\n",
      "fine-tuning (SFT) as a cold start. Furthermore, performance can be further enhanced with\n",
      "the inclusion of a small amount ...\n"
     ]
    }
   ],
   "source": [
    "results = client.query_points(\n",
    "    collection_name=\"deepseek_hybrid\",\n",
    "    prefetch=prefetch,\n",
    "    query=query_late,\n",
    "    using=\"colbert\",\n",
    "    with_payload=True,\n",
    "    limit=10\n",
    ").points\n",
    "\n",
    "for hit in results:\n",
    "    print(\"\\nCHUNK:\", hit.payload[\"chunk_id\"], \"SCORE:\", hit.score)\n",
    "    print(hit.payload[\"text\"][:400], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d77fc4-e16e-486a-a424-2b761170326c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f56e847-a6bd-4595-a907-b1e01bebc366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dense_collection(client, chunks, collection_name):\n",
    "    texts = [c.page_content for c in chunks]\n",
    "    ids = list(range(len(texts)))\n",
    "    payloads = [{\"chunk_id\": i, \"text\": texts[i]} for i in ids]\n",
    "\n",
    "    dense_vectors = list(dense_embedder.embed(texts))\n",
    "    dim = len(dense_vectors[0])\n",
    "\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=models.VectorParams(\n",
    "            size=dim,\n",
    "            distance=models.Distance.COSINE\n",
    "        )\n",
    "    )\n",
    "\n",
    "    client.upload_points(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=ids[i],\n",
    "                vector=dense_vectors[i],\n",
    "                payload=payloads[i]\n",
    "            )\n",
    "            for i in range(len(texts))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úì Dense collection created: {collection_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa27162a-79a9-4dc9-95a4-41d8e51197a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_collection(client, chunks, collection_name):\n",
    "    texts = [c.page_content for c in chunks]\n",
    "    ids = list(range(len(texts)))\n",
    "    payloads = [{\"chunk_id\": i, \"text\": texts[i]} for i in ids]\n",
    "\n",
    "    # Compute sparse vectors\n",
    "    bm25_vectors = list(sparse_embedder.embed(texts))\n",
    "\n",
    "    # Create collection (dense vectors disabled)\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={},   # <-- MUST be empty for sparse-only collection\n",
    "        sparse_vectors_config={\n",
    "            \"bm25\": models.SparseVectorParams(\n",
    "                modifier=models.Modifier.IDF\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Upload points\n",
    "    client.upload_points(\n",
    "        collection_name=collection_name,\n",
    "        points=[\n",
    "            models.PointStruct(\n",
    "                id=i,\n",
    "                vector={\"bm25\": bm25_vectors[i].as_object()},\n",
    "                payload=payloads[i]\n",
    "            )\n",
    "            for i in range(len(texts))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"‚úì Sparse BM25 collection created: {collection_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "142553b2-4aba-4594-8393-ce1930c4ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_model = TextEmbedding(\"jinaai/jina-embeddings-v2-small-en\") \n",
    "dense_model = TextEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\") \n",
    "sparse_model = SparseTextEmbedding(\"Qdrant/bm25\") \n",
    "late_model = LateInteractionTextEmbedding(\"colbert-ir/colbertv2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72817c13-d584-4fc3-9fd0-32504bb256a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hybrid_collection(client, chunks, collection_name):\n",
    "    print(f\"\\nBuilding hybrid collection: {collection_name}\")\n",
    "\n",
    "    documents = [c.page_content for c in chunks]\n",
    "    ids = list(range(len(documents)))\n",
    "\n",
    "    # Embed all three\n",
    "    dense_embeddings = list(dense_model.embed(documents))\n",
    "    bm25_embeddings = list(sparse_model.embed(documents))\n",
    "    late_embeddings = list(late_model.embed(documents))  # list of list-vectors\n",
    "\n",
    "    dense_dim = len(dense_embeddings[0])\n",
    "    late_dim = len(late_embeddings[0][0])  # each is multi-vector\n",
    "\n",
    "    # Recreate hybrid collection\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\n",
    "            \"Ball-MiniLM-L6-v2\": models.VectorParams(\n",
    "                size=dense_dim,\n",
    "                distance=models.Distance.COSINE\n",
    "            ),\n",
    "            \"colbert\": models.VectorParams(\n",
    "                size=late_dim,\n",
    "                distance=models.Distance.COSINE,\n",
    "                multivector_config=models.MultiVectorConfig(\n",
    "                    comparator=models.MultiVectorComparator.MAX_SIM\n",
    "                ),\n",
    "                hnsw_config=models.HnswConfigDiff(m=0)  # required for reranking\n",
    "            ),\n",
    "        },\n",
    "        sparse_vectors_config={\n",
    "            \"bm25\": models.SparseVectorParams(\n",
    "                modifier=models.Modifier.IDF\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Upsert points\n",
    "    points = []\n",
    "    for i in range(len(documents)):\n",
    "        points.append(\n",
    "            models.PointStruct(\n",
    "                id=i,\n",
    "                vector={\n",
    "                    \"Ball-MiniLM-L6-v2\": dense_embeddings[i],\n",
    "                    \"bm25\": bm25_embeddings[i].as_object(),\n",
    "                    \"colbert\": late_embeddings[i],\n",
    "                },\n",
    "                payload={\"chunk_id\": i, \"text\": documents[i]}\n",
    "            )\n",
    "        )\n",
    "\n",
    "    client.upsert(collection_name=collection_name, points=points)\n",
    "    print(f\"‚úì Hybrid collection created: {collection_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af00ecb0-435a-4649-b008-6e93b6a87018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Building collections for FIXED chunks ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/2099747660.py:9: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/4003400704.py:10: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dense collection created: deepseek_dense_fixed\n",
      "‚úì Sparse BM25 collection created: deepseek_sparse_fixed\n",
      "\n",
      "Building hybrid collection: deepseek_hybrid_fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1f/tbkzr71d44bg087cj88tj6_w0000gn/T/ipykernel_34752/2664358563.py:16: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Hybrid collection created: deepseek_hybrid_fixed\n",
      "\n",
      "=== Building collections for HEADING chunks ===\n",
      "‚úì Dense collection created: deepseek_dense_heading\n",
      "‚úì Sparse BM25 collection created: deepseek_sparse_heading\n",
      "\n",
      "Building hybrid collection: deepseek_hybrid_heading\n",
      "‚úì Hybrid collection created: deepseek_hybrid_heading\n"
     ]
    }
   ],
   "source": [
    "client = QdrantClient(path=\":memory:\")\n",
    "\n",
    "datasets = {\n",
    "    \"fixed\": fixed_chunks,\n",
    "    \"heading\": heading_chunks,\n",
    "}\n",
    "\n",
    "for mode, chunks in datasets.items():\n",
    "    print(f\"\\n=== Building collections for {mode.upper()} chunks ===\")\n",
    "    build_dense_collection(client, chunks, f\"deepseek_dense_{mode}\")\n",
    "    build_sparse_collection(client, chunks, f\"deepseek_sparse_{mode}\")\n",
    "    build_hybrid_collection(client, chunks, f\"deepseek_hybrid_{mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13f62118-2372-4507-a92e-8ad79e4c08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad0713bf-2b8f-4b41-8372-61e2ae144765",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ground_truth.json\", \"r\") as f:\n",
    "    ground_truth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b97c3609-e688-4fb4-a415-563f5f86aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_retriever(query, top_k=10, mode=\"fixed\"):\n",
    "    \"\"\"\n",
    "    mode = 'fixed' or 'heading'\n",
    "    \"\"\"\n",
    "    collection_name = f\"deepseek_dense_{mode}\"\n",
    "\n",
    "    # Compute query vector\n",
    "    query_vec = next(dense_embedder.embed([query]))\n",
    "\n",
    "    # Query Qdrant\n",
    "    hits = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vec,\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    ).points\n",
    "\n",
    "    return hits   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8daabe9-b7f3-459d-a358-024c26c2b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_retriever(query, top_k=10, mode=\"fixed\"):\n",
    "    collection_name = f\"deepseek_sparse_{mode}\"\n",
    "\n",
    "    query_sparse = next(sparse_embedder.query_embed(query))\n",
    "\n",
    "    hits = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.SparseVector(**query_sparse.as_object()),\n",
    "        using=\"bm25\",                # <-- REQUIRED\n",
    "        limit=top_k,\n",
    "        with_payload=True\n",
    "    ).points\n",
    "\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6956b30-ef55-4266-9c0f-1ef0bd7b404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_retriever(query, top_k=10, mode=\"fixed\"):\n",
    "    collection_name = f\"deepseek_hybrid_{mode}\"\n",
    "\n",
    "    # embed query in all 3 ways\n",
    "    q_dense = next(dense_model.query_embed(query))\n",
    "    q_sparse = next(sparse_model.query_embed(query))\n",
    "    q_late = next(late_model.query_embed(query))  # for rerank\n",
    "\n",
    "    prefetch = [\n",
    "        models.Prefetch(\n",
    "            query=q_dense,\n",
    "            using=\"Ball-MiniLM-L6-v2\",\n",
    "            limit=20\n",
    "        ),\n",
    "        models.Prefetch(\n",
    "            query=models.SparseVector(**q_sparse.as_object()),\n",
    "            using=\"bm25\",\n",
    "            limit=20\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        prefetch=prefetch,\n",
    "        query=q_late,\n",
    "        using=\"colbert\",\n",
    "        with_payload=True,\n",
    "        limit=top_k\n",
    "    ).points\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e059b72-df89-4222-b7cb-7a61c2177254",
   "metadata": {},
   "source": [
    "Áî® embedding similarityÔºàÂêëÈáèÁõ∏‰ººÂ∫¶ÔºâÊâæÂà∞‚ÄúÊúÄÂåπÈÖçÁöÑ chunk‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa331923-3f03-4a94-afff-f5147fd9eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_texts_fixed = [c.page_content for c in fixed_chunks]\n",
    "chunk_texts_heading = [c.page_content for c in heading_chunks]\n",
    "\n",
    "chunk_emb_fixed = list(dense_embedder.embed(chunk_texts_fixed))\n",
    "chunk_emb_heading = list(dense_embedder.embed(chunk_texts_heading))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed778d43-0972-471e-adad-820ea475c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ground_truth:\n",
    "    ans_emb = next(dense_embedder.embed([item[\"answer\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d00260da-6ee6-496c-a9c2-cc829f4a2288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a25965f-3441-460f-b3f6-7a0cbc972738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunk_by_embedding(ans_emb, chunk_emb_list):\n",
    "    sims = [cosine_sim(ans_emb, emb) for emb in chunk_emb_list]\n",
    "    return int(np.argmax(sims))   # pick best match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83e1aac9-3d12-4970-95b7-5b5a0f992a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ground_truth:\n",
    "    ans_emb = next(dense_embedder.embed([item[\"answer\"]]))\n",
    "\n",
    "    item[\"fixed_chunk_id\"] = find_chunk_by_embedding(ans_emb, chunk_emb_fixed)\n",
    "    item[\"heading_chunk_id\"] = find_chunk_by_embedding(ans_emb, chunk_emb_heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd1be3d4-5e25-4ab0-b330-b7eafe1164dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q01 20 7\n",
      "q02 66 33\n",
      "q03 23 9\n",
      "q04 22 32\n",
      "q05 26 4\n",
      "q06 74 58\n",
      "q07 74 55\n",
      "q08 40 40\n",
      "q09 38 56\n",
      "q10 40 55\n",
      "q11 53 3\n",
      "q12 58 55\n",
      "q13 2 3\n",
      "q14 53 46\n",
      "q15 28 27\n",
      "q16 48 45\n",
      "q17 16 45\n",
      "q18 41 41\n",
      "q19 55 20\n",
      "q20 58 27\n"
     ]
    }
   ],
   "source": [
    "for item in ground_truth:\n",
    "    print(item[\"id\"], item[\"fixed_chunk_id\"], item[\"heading_chunk_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4a16313-894c-4bc8-bf98-b7d386aad142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because neural reward models may suffer from reward hacking during large-scale RL and require extra retraining, complicating the training pipeline.\n",
      "-----\n",
      "2.2.2. Reward Modeling\n",
      "The reward is the source of the training signal, which decides the optimization direction of RL.\n",
      "To train DeepSeek-R1-Zero, we adopt a rule-based reward system that mainly consists of two\n",
      "types of rewards:\n",
      "‚Ä¢ Accuracy rewards: The accuracy reward model evaluates whether the response is correct.\n",
      "For example, in the case of math problems with deterministic results, the model is required\n",
      "to provide the final answer in a specified format (e.g., within a box), enabling reliable\n",
      "rule-based verification of correctness. Similarly, for LeetCode problems, a compiler can be\n",
      "used to generate feedback based on predefined test cases.\n",
      "‚Ä¢ Format rewards: In addition to the accuracy reward model, we employ a format reward\n",
      "model that enforces the model to put its thinking process between ‚Äò<think>‚Äô and ‚Äò</think>‚Äô\n",
      "tags.\n",
      "We do not apply the outcome or process neural reward model in developing DeepSeek-R1-Zero,\n",
      "because we find that the neural reward model may suffer from reward hacking in the large-scale\n",
      "reinforcement learning process, and retraining the reward model needs additional training\n",
      "resources and it complicates the whole training pipeline.\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth[1][\"answer\"])\n",
    "print(\"-----\")\n",
    "print(heading_chunks[ground_truth[1][\"heading_chunk_id\"]].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f2aee857-7184-40ca-b826-961591766138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank(ranked_ids, true_id):\n",
    "    for rank, rid in enumerate(ranked_ids, start=1):\n",
    "        if rid == true_id:\n",
    "            return 1 / rank\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b9cff0f-eef8-4489-8f55-dc93a6fdc074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(method_name, retriever_fn, gt_data, chunk_mode, ks=[1,3,5,10]):\n",
    "    results = {f\"hit@{k}\": 0 for k in ks}\n",
    "    results[\"MRR\"] = 0\n",
    "    total = len(gt_data)\n",
    "\n",
    "    for item in gt_data:\n",
    "        true_id = item[f\"{chunk_mode}_chunk_id\"]\n",
    "        if true_id is None:\n",
    "            continue\n",
    "\n",
    "        hits = retriever_fn(item[\"question\"], top_k=max(ks), mode=chunk_mode)\n",
    "        retrieved_ids = [h.payload[\"chunk_id\"] for h in hits]\n",
    "\n",
    "        for k in ks:\n",
    "            if true_id in retrieved_ids[:k]:\n",
    "                results[f\"hit@{k}\"] += 1\n",
    "\n",
    "        results[\"MRR\"] += reciprocal_rank(retrieved_ids, true_id)\n",
    "\n",
    "    # normalize\n",
    "    for k in ks:\n",
    "        results[f\"hit@{k}\"] /= total\n",
    "    results[\"MRR\"] /= total\n",
    "\n",
    "    results[\"method\"] = method_name\n",
    "    results[\"chunking\"] = chunk_mode\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9ed0b04-bfee-4c61-a228-33d815b4a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = []\n",
    "\n",
    "methods = [\n",
    "    (\"Dense\", dense_retriever),\n",
    "    (\"Sparse\", sparse_retriever),\n",
    "    (\"Hybrid\", hybrid_retriever)\n",
    "]\n",
    "\n",
    "for name, fn in methods:\n",
    "    eval_results.append(evaluate(name, fn, ground_truth, chunk_mode=\"fixed\"))\n",
    "    eval_results.append(evaluate(name, fn, ground_truth, chunk_mode=\"heading\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3e2217e-cd72-444a-b4c9-4c669d4b4b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>chunking</th>\n",
       "      <th>hit@1</th>\n",
       "      <th>hit@3</th>\n",
       "      <th>hit@5</th>\n",
       "      <th>hit@10</th>\n",
       "      <th>MRR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dense</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.214583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dense</td>\n",
       "      <td>heading</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.094444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.351865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>heading</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.190060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hybrid</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.252758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hybrid</td>\n",
       "      <td>heading</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.210000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method chunking  hit@1  hit@3  hit@5  hit@10       MRR\n",
       "0   Dense    fixed   0.20   0.20   0.20    0.30  0.214583\n",
       "1   Dense  heading   0.05   0.15   0.15    0.25  0.094444\n",
       "2  Sparse    fixed   0.30   0.35   0.45    0.55  0.351865\n",
       "3  Sparse  heading   0.10   0.25   0.30    0.40  0.190060\n",
       "4  Hybrid    fixed   0.20   0.25   0.30    0.50  0.252758\n",
       "5  Hybrid  heading   0.10   0.30   0.35    0.35  0.210000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(eval_results)\n",
    "df = df[[\"method\", \"chunking\", \"hit@1\", \"hit@3\", \"hit@5\", \"hit@10\", \"MRR\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776d9c3-71ac-4206-b41c-b12824f0986c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d93f2d-791f-4ca6-9081-f8d819591ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f47e4e-da2e-4bf5-8eb8-fc8b207e4ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag-challenge)",
   "language": "python",
   "name": "rag-challenge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
